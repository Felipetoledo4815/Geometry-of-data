{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data and plot it\n",
    "\n",
    "Note how the data is loaded with `train = True`. You can load the test data in a similar fashion, just set `train = False`. Feel free to reuse my plot function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 100\n",
    "train_data = FashionMNIST(\"./data\", train = True, download = True,\n",
    "                          transform=transforms.ToTensor())\n",
    "data_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "width = 28\n",
    "height = 28\n",
    "input_size = width * height\n",
    "\n",
    "def plot_images(batch, rows, cols, title = \"\"):\n",
    "    plt.figure(figsize = (rows, cols))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(np.transpose(\n",
    "        vutils.make_grid(batch[:(rows * cols)], nrow = rows, normalize = True).cpu(),\n",
    "        (1, 2, 0)))\n",
    "\n",
    "first_batch = next(iter(data_loader))\n",
    "plot_images(first_batch[0], 10, 10, \"Some Training Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedAutoencoder(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super(FullyConnectedAutoencoder, self).__init__()\n",
    "        self.elayer1 = nn.Linear(input_size, 256)\n",
    "        self.ebatch1 = nn.BatchNorm1d(256)\n",
    "        self.elayer2 = nn.Linear(256, 128)\n",
    "        self.ebatch2 = nn.BatchNorm1d(128)\n",
    "        self.elayer3 = nn.Linear(128, out_size)\n",
    "\n",
    "        self.dlayer1 = nn.Linear(out_size, 128)\n",
    "        self.dbatch1 = nn.BatchNorm1d(128)\n",
    "        self.dlayer2 = nn.Linear(128, 256)\n",
    "        self.dbatch2 = nn.BatchNorm1d(256)\n",
    "        self.dlayer3 = nn.Linear(256, input_size)\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        y1 = F.elu(self.ebatch1(self.elayer1(x)))\n",
    "        y2 = F.elu(self.ebatch2(self.elayer2(y1)))\n",
    "        z = F.elu(self.elayer3(y2))\n",
    "        return z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        y1 = F.elu(self.dbatch1(self.dlayer1(z)))\n",
    "        y2 = F.elu(self.dbatch2(self.dlayer2(y1)))\n",
    "        x = torch.sigmoid(self.dlayer3(y2))\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, input_size)\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z)\n",
    "        y = y.view(-1, 1, width, height)\n",
    "        return y\n",
    "\n",
    "class ConvolutionalAutoencoder(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super(ConvolutionalAutoencoder, self).__init__()\n",
    "        self.econv1 = nn.Conv2d(1, 32, kernel_size = 5, bias = False)\n",
    "        self.ebatch1 = nn.BatchNorm2d(32)\n",
    "        self.econv2 = nn.Conv2d(32, 8, kernel_size = 5, bias = False)\n",
    "        self.ebatch2 = nn.BatchNorm2d(8)\n",
    "        self.econv3 = nn.Conv2d(8, out_size, kernel_size = 20, bias = True)\n",
    "\n",
    "        self.dconv1 = nn.ConvTranspose2d(out_size, 8, kernel_size = 20, bias = True)\n",
    "        self.dbatch1 = nn.BatchNorm2d(8)\n",
    "        self.dconv2 = nn.ConvTranspose2d(8, 32, kernel_size = 5, bias = False)\n",
    "        self.dbatch2 = nn.BatchNorm2d(32)\n",
    "        self.dconv3 = nn.ConvTranspose2d(32, 1, kernel_size = 5, bias = False)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        y1 = F.elu(self.ebatch1(self.econv1(x)))\n",
    "        y2 = F.elu(self.ebatch2(self.econv2(y1)))\n",
    "        z = F.elu(self.econv3(y2))\n",
    "        return z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        y1 = F.elu(self.dbatch1(self.dconv1(z)))\n",
    "        y2 = F.elu(self.dbatch2(self.dconv2(y1)))\n",
    "        x = torch.sigmoid(self.dconv3(y2))\n",
    "        return x\n",
    "     \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    "The rest of the code below trains the models. Do not include this code in your solution and don't run it! (it takes forever without a GPU) Instead load the pre-trained models from the course website. This is included in case you want to see how I trained the models, and if you want to play with them beyond what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, num_epochs = 20, learn_rate = 0.5):\n",
    "    optimizer = torch.optim.SGD(autoencoder.parameters(), lr = learn_rate)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        tot_loss = 0\n",
    "        for i, (x, label) in enumerate(data_loader):\n",
    "            x = x.to(device)\n",
    "            y = autoencoder(x)\n",
    "\n",
    "            loss = mse_loss(x, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tot_loss = tot_loss + loss.data.cpu().numpy()\n",
    "\n",
    "        print(epoch, \": Loss =\", tot_loss)\n",
    "        \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcAE16 = FullyConnectedAutoencoder(16)\n",
    "fcAE16 = train(fcAE16.to(device))\n",
    "torch.save(fcAE16.state_dict(), \"fcAE16.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcAE32 = FullyConnectedAutoencoder(32)\n",
    "fcAE32 = train(fcAE32.to(device))\n",
    "torch.save(fcAE32.state_dict(), \"fcAE32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcAE128 = FullyConnectedAutoencoder(128)\n",
    "fcAE128 = train(fcAE128.to(device))\n",
    "torch.save(fcAE128.state_dict(), \"fcAE128.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convAE16 = ConvolutionalAutoencoder(16)\n",
    "convAE16 = train(convAE16.to(device))\n",
    "torch.save(convAE16.state_dict(), \"convAE16.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convAE32 = ConvolutionalAutoencoder(32)\n",
    "convAE32 = train(convAE32.to(device))\n",
    "torch.save(convAE32.state_dict(), \"convAE32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convAE128 = ConvolutionalAutoencoder(128)\n",
    "convAE128 = train(convAE128.to(device))\n",
    "torch.save(convAE128.state_dict(), \"convAE128.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
